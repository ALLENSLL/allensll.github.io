<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-03-26T20:43:37+08:00</updated><id>http://localhost:4000/</id><title type="html">allensll</title><subtitle>HomePage</subtitle><entry><title type="html">A note about installing tensorflow</title><link href="http://localhost:4000/Installing-Tensorflow-on-Ubuntu/" rel="alternate" type="text/html" title="A note about installing tensorflow" /><published>2018-03-25T00:00:00+08:00</published><updated>2018-03-25T00:00:00+08:00</updated><id>http://localhost:4000/Installing-Tensorflow-on-Ubuntu</id><content type="html" xml:base="http://localhost:4000/Installing-Tensorflow-on-Ubuntu/">&lt;p&gt;Recently, I want to use a pre-trained faster-rcnn to finish a persion dection task. As a beginner of Deep learning, I need to install Tensorflow in my computer, and it took me two days, so I decid to record the installation steps.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/install/&quot;&gt;Tensorflow’s Official Guide&lt;/a&gt; is the first and the most important doc you should read.&lt;/p&gt;

&lt;h3 id=&quot;my-device-and-version&quot;&gt;My device and version&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Ubuntu 16.04&lt;/li&gt;
  &lt;li&gt;GeForce GT 710&lt;/li&gt;
  &lt;li&gt;CUDA Toolkit 9.0&lt;/li&gt;
  &lt;li&gt;cuDNN v7.0.5&lt;/li&gt;
  &lt;li&gt;Python 3.6&lt;/li&gt;
  &lt;li&gt;Tensorflow 1.6&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-1-installing-os&quot;&gt;Step 1 installing OS&lt;/h3&gt;

&lt;p&gt;Tensorflow certainlly supports all commmon OS, and I choice Ubuntu 16.04 whitch same as official guide. There are two things need to be concerned&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If you use a WiFi adapter to connect network, you should plug adapter into computer before run the installer, and then installer will automatically install and load suitable kernel modules.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CUDA Toolkit 9.0 request at least Kernel 4.4 for Ubuntu 16.04, so I should update Kernel after install Ubuntu. All mainline kernel build can be downloaded &lt;a href=&quot;http://kernel.ubuntu.com/~kernel-ppa/mainline/&quot;&gt;here&lt;/a&gt; you can use wget command to download kernel.&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.124/linux-headers-4.4.124-0404124_4.4.124-0404124.201803250430_all.deb
wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.124/linux-headers-4.4.124-0404124-generic_4.4.124-0404124.201803250430_amd64.deb
wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.124/linux-image-4.4.124-0404124-generic_4.4.124-0404124.201803250430_amd64.deb
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;install the packages.&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;dpkg -i *.deb
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;update grub and reboot the system.&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;sudo update-grub
sudo reboot
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;check the kernel version.&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;uname -r
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-2-installing-nvidia-software&quot;&gt;Step 2 installing NVIDIA software&lt;/h3&gt;

&lt;p&gt;In this step, two software, &lt;a href=&quot;http://docs.nvidia.com/cuda/&quot;&gt;CUDA Toolkit&lt;/a&gt; and &lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;cuDNN&lt;/a&gt; will be installed, but first verify you have a CUDA-Capable GPU and Tensorflow only support whitch &lt;strong&gt;compute capability &amp;gt;= 3.0&lt;/strong&gt;. See &lt;a href=&quot;https://developer.nvidia.com/cuda-gpus&quot;&gt;here&lt;/a&gt; for a list of supported GPU cards. I don’t find GT 710 in that list, so just google GT 710 to find the answer.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;installing CUDA Tookit 9.0&lt;/strong&gt;. The NVIDIA drivers associated with CUDA Toolkit, so don’t need to install it alone. It is easy to encounter problems at this step.
    &lt;ol&gt;
      &lt;li&gt;Check prerequisite before install.&lt;/li&gt;
      &lt;li&gt;Download the &lt;a href=&quot;http://developer.nvidia.com/cuda-downloads&quot;&gt;NVIDIA CUDA Toolkit&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Disable Noveau drivers.&lt;br /&gt;
  pushing &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl&lt;/code&gt;+&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt&lt;/code&gt;+&lt;code class=&quot;highlighter-rouge&quot;&gt;F1&lt;/code&gt; and login,&lt;br /&gt;
  type &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo service lightdm stop&lt;/code&gt;,&lt;br /&gt;
  create a file: &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/modprobe.d/blacklist-nouveau.conf&lt;/code&gt; and type follow:
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  blacklist nouveau
  options nouveau modeset=0
&lt;/code&gt;&lt;/pre&gt;
        &lt;p&gt;reboot and verify Noveau not loaded.&lt;/p&gt;
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  lsmod | grep nouveau
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;install cuda.
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb
  sudo apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub
  sudo apt-get update
  sudo apt-get install cuda
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;reboot and check install
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  nvidia-smi
  nvcc --version
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;installing cuDNN v7.0.5&lt;/strong&gt;. Read &lt;a href=&quot;http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html&quot;&gt;cuDNN Installation Guide&lt;/a&gt; to learn more detials.
    &lt;ol&gt;
      &lt;li&gt;Check prerequisite before install.&lt;/li&gt;
      &lt;li&gt;download &lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;cuDNN&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;install cuDNN.
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  sudo dpkg -i libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;set path variables. Add these lines to end of &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt; and reboot
        &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;  export PATH=/usr/local/cuda/bin${PATH:+:PATH}
  export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
  export CUDA_HOME=/usr/local/cuda
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-3-installing-tensorflow&quot;&gt;Step 3 installing Tensorflow&lt;/h3&gt;

&lt;p&gt;I use Anaconda environment to use Tensorflow, type the following instructions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;conda create -n tensorflow pip python=3.6
source activate tensorflow
pip install tensorflow-gpu -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;step-4-test-tensorflow&quot;&gt;Step 4 test Tensorflow&lt;/h3&gt;

&lt;p&gt;type the following python code to test Tensorflow.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-Python&quot;&gt;import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print sess.run(hello)
# Hello, TensorFlow!
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;external-links&quot;&gt;&lt;em&gt;External links&lt;/em&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/zhaoyu106/article/details/52793183&quot;&gt;https://blog.csdn.net/zhaoyu106/article/details/52793183&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/williamFalcon/tensorflow-gpu-install-ubuntu-16.04&quot;&gt;https://github.com/williamFalcon/tensorflow-gpu-install-ubuntu-16.04&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Recently, I want to use a pre-trained faster-rcnn to finish a persion dection task. As a beginner of Deep learning, I need to install Tensorflow in my computer, and it took me two days, so I decid to record the installation steps.</summary></entry><entry><title type="html">A brief introduction to Dimensionality Reduction</title><link href="http://localhost:4000/Dimensionality-Reduction/" rel="alternate" type="text/html" title="A brief introduction to Dimensionality Reduction" /><published>2017-09-25T00:00:00+08:00</published><updated>2017-09-25T00:00:00+08:00</updated><id>http://localhost:4000/Dimensionality-Reduction</id><content type="html" xml:base="http://localhost:4000/Dimensionality-Reduction/">&lt;p&gt;Dimensionality reduction can be divided  into &lt;em&gt;feature selection&lt;/em&gt; and &lt;em&gt;feature extraction&lt;/em&gt;, this text concerns about feature extraction, for feature extraction, there are &lt;em&gt;linear dimensionality reduction&lt;/em&gt; and &lt;em&gt;nonlinear dimensionality reduction&lt;/em&gt; techniques.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;linear dimensionality reduction&lt;/em&gt;: PCA&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;nonlinear dimensionality reduction&lt;/em&gt;: MDS Isomap LLE&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;principal-component-analysis&quot;&gt;Principal component analysis&lt;/h3&gt;

&lt;p&gt;Principal Component Analysis a classical technique for dimensionality reducion, Goal of PCA is to find an orthogonal linear transformation that transforms the data to a new coordinates system such that the greatest variance by some projection of the data comes to lie on the first coordinate(called the first principal component), the second greatest variance on the second coordinate, and so on.
we can generalize PCA to four steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Step 1. Centering the data&lt;/li&gt;
  &lt;li&gt;Step 2. Find the covariance matrix&lt;/li&gt;
  &lt;li&gt;Step 3. Calculate the eigenvectors and eigenvalues of the covariance matrix&lt;/li&gt;
  &lt;li&gt;Step 4. Select principal component and form a transformational matrix&lt;/li&gt;
  &lt;li&gt;Step 5. Calculate the new data&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bibliography--external-links&quot;&gt;&lt;em&gt;Bibliography &amp;amp; External links&lt;/em&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Dimensionality_reduction&quot;&gt;“Dimensionality reduction”&lt;/a&gt;. wikipedia.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;“Principal Component Analysis”&lt;/a&gt;. wikipedia.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://luthuli.cs.uiuc.edu/~daf/courses/CS-498-DAF-PS/Lecture%209%20-%20PCA.pdf&quot;&gt;UIUC CS498 Lecture 9 - PCA.pdf&lt;/a&gt;. cs.illinois.edu&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf&quot;&gt;“A tutorial on Principal Components Analysis”&lt;/a&gt;. cs.otago.ac.nz.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ams.org/samplings/feature-column/fcarc-svd&quot;&gt;“We Recommend a Singular Value Decomposition”&lt;/a&gt;. ams.org.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multidimensional-scaling&quot;&gt;Multidimensional Scaling&lt;/h3&gt;

&lt;p&gt;Multidimensional Scaling is a form of non-linear dimensionality reduction. Goal of Multidimensional scaling: given raw data‘s pairwise dissmilarities, reconstruct a map that preserves distances. MDS is a family of different algorithms, including Classsical MDS, Metric MDS, Non-metric MDS. When using Classical MDS, you need to do a eigenvalue decomposion for the coordinate matrix. So essentially Classical MDS do the same thing like PCA. Classical MDS assumes Euclidean distances. So this is not applicable for direct dissimilarity ratings.&lt;/p&gt;

&lt;p&gt;Classical MDS try to find an optional configuration &lt;script type=&quot;math/tex&quot;&gt;x_{i}&lt;/script&gt; that gives &lt;script type=&quot;math/tex&quot;&gt;d_{ij} \approx \hat{d}_{ij} = \left \lVert x_{i} - x_{j} \right \rVert _{2}&lt;/script&gt; as close as possible. Let’s relaxing Classical MDS by allowing &lt;script type=&quot;math/tex&quot;&gt;d_{ij} \approx \hat{d}_{ij} \approx f(d_{ij})&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is a monotone function(&lt;a href=&quot;https://en.wikipedia.org/wiki/Isotonic_regression&quot;&gt;Isotonic regression&lt;/a&gt;). we named it as metric MDS if dissimilarities &lt;script type=&quot;math/tex&quot;&gt;d_{ij}&lt;/script&gt; are quantitative and non-metric MDS if &lt;script type=&quot;math/tex&quot;&gt;d_{ij}&lt;/script&gt; are qualitative. Unlike Classical MDS, metric or non-metric MDS is an optimization process(&lt;a href=&quot;https://en.wikipedia.org/wiki/Stress_majorization&quot;&gt;Stress majorization&lt;/a&gt;) minimzing stress function, and is solved by iterative algorithms.&lt;/p&gt;

&lt;h4 id=&quot;bibliography--extermal-links&quot;&gt;&lt;em&gt;Bibliography &amp;amp; Extermal links&lt;/em&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction&quot;&gt;“Nonlinear dimensionality reduction”&lt;/a&gt;. wikipedia.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Multidimensional_scaling&quot;&gt;“Multidimensional Scaling”&lt;/a&gt;. wikipedia.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.stat.pitt.edu/sungkyu/course/2221Fall13/lec8_mds_combined.pd&quot;&gt;PITT STAT 2221 Lecture 8: Multidimensional scaling&lt;/a&gt;. stat.pitt.edu.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;isomap&quot;&gt;Isomap&lt;/h3&gt;

&lt;p&gt;Isomap and LLE bring research boom of manifold learning—is usually considered to be a branch of the nonlinear dimensionality reduction. Goal of Isomap is to find an isometric mapping configuration and keep the &lt;a href=&quot;https://en.wikipedia.org/wiki/Geographical_distance&quot;&gt;geodesic distances&lt;/a&gt; on the manifold. we can generalize Isomap to two steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Step 1. Calculate the geodesic distances
    &lt;ul&gt;
      &lt;li&gt;Determine the neighbors of each point&lt;/li&gt;
      &lt;li&gt;Construct a neighborhood graph&lt;/li&gt;
      &lt;li&gt;Compute shortest path between two nodes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Step 2. Compute lower-dimensional embedding
    &lt;ul&gt;
      &lt;li&gt;use MDS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bibliography--external-links-1&quot;&gt;&lt;em&gt;Bibliography &amp;amp; External links&lt;/em&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Isomap&quot;&gt;“Isomap”&lt;/a&gt;. wikipedia.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://web.mit.edu/cocosci/isomap/isomap.html&quot;&gt;“A Global Geometric Framework for Nonlinear Dimensionality Reduction”&lt;/a&gt;. mit.edu.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cad.zju.edu.cn/reports/%C1%F7%D0%CE%D1%A7%CF%B0.pdf&quot;&gt;“流形学习” ZJU 何晓飞&lt;/a&gt;. cad.zju.edu.cn.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;locally-linear-embedding&quot;&gt;Locally Linear Embedding&lt;/h3&gt;

&lt;p&gt;Locally Linear Embedding is a milestone in nonlinear dimensionality reduction. LLE tends to handle non-uniform sample densities poorly because there is no fixed unit to prevent the weights from drifting as various regions differ in sample densities.&lt;/p&gt;

&lt;h4 id=&quot;bibliography--external-links-2&quot;&gt;&lt;em&gt;Bibliography &amp;amp; External links&lt;/em&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.nyu.edu/~roweis/lle/&quot;&gt;“Locally Linear Embedding”&lt;/a&gt;. cs.nyu.edu.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.nyu.edu/~roweis/lle/papers/lleintro.pdf&quot;&gt;Saul, Lawrence K., and Sam T. Roweis. “An introduction to locally linear embedding.”&lt;/a&gt; unpublished. Available at: http://www. cs. toronto. edu/~ roweis/lle/publications. html (2000).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/papers/volume4/saul03a/saul03a.pdf&quot;&gt;Think globally, fit locally: unsupervised learning of low dimensional manifolds&lt;/a&gt;. jmlr.org.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint&quot;&gt;“Lagrange multipliers”&lt;/a&gt;. khanacademy.org.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Dimensionality reduction can be divided into feature selection and feature extraction, this text concerns about feature extraction, for feature extraction, there are linear dimensionality reduction and nonlinear dimensionality reduction techniques.</summary></entry></feed>